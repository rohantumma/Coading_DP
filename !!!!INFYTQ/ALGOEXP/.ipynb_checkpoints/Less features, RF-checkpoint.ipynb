{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Less features, random Forest\n",
    "\n",
    "Same features in https://github.com/diogodutra/COVID-19-Albert_Eintein/blob/master/COVID-19_Albert_Einstein.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    mean_absolute_error\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"E:/rohan/CSE 6/covid-19-master/covid-19-master/dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5644, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'Leukocytes',\n",
    "    'Monocytes',\n",
    "    'Platelets',\n",
    "    'Patient age quantile',\n",
    "]\n",
    "\n",
    "df_clean = df[features + [\"SARS-Cov-2 exam result\"]]\n",
    "\n",
    "print(df_clean.shape)\n",
    "\n",
    "# predicted label as simple integers\n",
    "df_clean[\"SARS-Cov-2 exam result\"].replace(\"positive\", 1, inplace=True)\n",
    "df_clean[\"SARS-Cov-2 exam result\"].replace(\"negative\", 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 5)\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_clean.dropna()\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean.drop(\"SARS-Cov-2 exam result\", axis=1)\n",
    "y = df_clean[\"SARS-Cov-2 exam result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29434284, 0.37647056, 0.16839917, 0.89473684],\n",
       "       [0.36452575, 0.33333333, 0.32952185, 0.05263158],\n",
       "       [0.1735432 , 0.51372545, 0.17567568, 0.47368421],\n",
       "       ...,\n",
       "       [0.2245853 , 0.45882351, 0.17047818, 0.78947368],\n",
       "       [0.04381117, 0.52941174, 0.06444907, 0.89473684],\n",
       "       [0.11186731, 0.40784312, 0.13617464, 1.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    411\n",
      "1     69\n",
      "Name: SARS-Cov-2 exam result, dtype: int64\n",
      "0    107\n",
      "1     14\n",
      "Name: SARS-Cov-2 exam result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_feature_importance(model, features):\n",
    "    if not hasattr(model, \"coef_\") and not hasattr(model, \"feature_importances_\"):\n",
    "        raise Exception(\"Not possible to collect feature importances\")\n",
    "\n",
    "    if hasattr(model, \"coef_\"):\n",
    "        model_feature_importances = model.coef_[0]\n",
    "    elif hasattr(model, \"feature_importances_\"):\n",
    "        model_feature_importances = model.feature_importances_\n",
    "\n",
    "    return [\n",
    "        (feature, importance)\n",
    "        for feature, importance in sorted(\n",
    "            zip(features, model_feature_importances),\n",
    "            key=lambda pair: pair[1],\n",
    "            reverse=True,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "def run_single(X_train, y_train, X_test, y_test, which_model):\n",
    "\n",
    "    model = which_model[\"model\"]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # let us just print the performance on the train set\n",
    "    predictions_train = model.predict(X_train)\n",
    "    train_results = {\n",
    "        \"prec\": precision_score(y_train, predictions_train),\n",
    "        \"rec\": recall_score(y_train, predictions_train),\n",
    "        \"roc\": roc_auc_score(y_train, predictions_train),\n",
    "    }\n",
    "    cm_train = confusion_matrix(y_train, predictions_train)\n",
    "    \n",
    "    # in the test set\n",
    "    predictions_test = model.predict(X_test)\n",
    "    test_results = {\n",
    "        \"prec\": precision_score(y_test, predictions_test),\n",
    "        \"rec\": recall_score(y_test, predictions_test),\n",
    "        \"roc\": roc_auc_score(y_test, predictions_test),\n",
    "    }\n",
    "\n",
    "    cm_test = confusion_matrix(y_test, predictions_test)\n",
    "    \n",
    "    # feature importance\n",
    "    feature_importance = _extract_feature_importance(model, X_train.columns.values)\n",
    "    \n",
    "    return {\n",
    "        \"test_results\": test_results, \n",
    "        \"train_results\": train_results, \n",
    "        \"test_cm\" : cm_test,\n",
    "        \"train_cm\" : cm_train,\n",
    "        \"feature_importance\": feature_importance,\n",
    "        \"y_pred\": predictions_test,\n",
    "        \"model\": model\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def run_cv(X_train, y_train, X_test, y_test, which_model):\n",
    "\n",
    "    K_FOLD_ITERATIONS = 10\n",
    "\n",
    "    search = GridSearchCV(\n",
    "        which_model[\"model\"], \n",
    "        which_model[\"params_to_tune\"], \n",
    "        scoring=\"roc_auc\",\n",
    "        cv=StratifiedKFold(\n",
    "            n_splits=K_FOLD_ITERATIONS, \n",
    "            shuffle=True),  \n",
    "        n_jobs=-1)\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    model = search.best_estimator_\n",
    "\n",
    "    # let us just print the performance on the train set\n",
    "    predictions_train = model.predict(X_train)\n",
    "    train_results = {\n",
    "        \"prec\": precision_score(y_train, predictions_train),\n",
    "        \"rec\": recall_score(y_train, predictions_train),\n",
    "        \"roc\": roc_auc_score(y_train, predictions_train),\n",
    "        \"mae\": mean_absolute_error(y_train, predictions_train),\n",
    "    }\n",
    "    cm_train = confusion_matrix(y_train, predictions_train)\n",
    "    \n",
    "    # in the test set\n",
    "    predictions_test = model.predict(X_test)\n",
    "    test_results = {\n",
    "        \"prec\": precision_score(y_test, predictions_test),\n",
    "        \"rec\": recall_score(y_test, predictions_test),\n",
    "        \"roc\": roc_auc_score(y_test, predictions_test),\n",
    "        \"mae\": mean_absolute_error(y_test, predictions_test),\n",
    "    }\n",
    "    cm_test = confusion_matrix(y_test, predictions_test)\n",
    "    \n",
    "    # feature importance\n",
    "    feature_importance = _extract_feature_importance(model, X_train.columns.values)\n",
    "    \n",
    "    return {\n",
    "        \"test_results\": test_results, \n",
    "        \"train_results\": train_results, \n",
    "        \"test_cm\" : cm_test,\n",
    "        \"train_cm\" : cm_train,\n",
    "        \"feature_importance\": feature_importance,\n",
    "        \"y_pred\": predictions_test,\n",
    "        \"model\": model,\n",
    "        \"search\": search\n",
    "    }\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def print_result(result, fi=True):\n",
    "    print(\"Results in the training set\")\n",
    "    print(result[\"train_results\"])\n",
    "    print(result[\"train_cm\"])\n",
    "    print(\"Results in the test set\")\n",
    "    print(result[\"test_results\"])\n",
    "    print(result[\"test_cm\"])\n",
    "    \n",
    "    print(\"Report:\")\n",
    "    print(classification_report(y_test,result[\"y_pred\"]))\n",
    "    \n",
    "    if fi:\n",
    "        print(\"Feature importances\")\n",
    "        pd_fi = pd.DataFrame(result[\"feature_importance\"], columns=[\"feature\", \"importance\"])\n",
    "        pd_fi = pd_fi[(pd_fi.importance > 0.01)]\n",
    "\n",
    "        p = plt.barh(pd_fi[\"feature\"], pd_fi[\"importance\"])\n",
    "        print(p)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = {\n",
    "    \"model\": RandomForestClassifier(random_state=42),\n",
    "    \"params_to_tune\": {\n",
    "        \"max_depth\": [2, 3, 4, 5, 6, 7, 10, 12, None],\n",
    "        \"min_samples_split\": [2, 3, 4, 5],\n",
    "        \"bootstrap\": [True, False],\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"n_estimators\": [50, 100, 150, 200]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_cv(X_train, y_train, X_test, y_test, rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results in the training set\n",
      "{'prec': 1.0, 'rec': 0.782608695652174, 'roc': 0.8913043478260869, 'mae': 0.03125}\n",
      "[[411   0]\n",
      " [ 15  54]]\n",
      "Results in the test set\n",
      "{'prec': 0.75, 'rec': 0.42857142857142855, 'roc': 0.7049399198931909, 'mae': 0.08264462809917356}\n",
      "[[105   2]\n",
      " [  8   6]]\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       107\n",
      "           1       0.75      0.43      0.55        14\n",
      "\n",
      "    accuracy                           0.92       121\n",
      "   macro avg       0.84      0.70      0.75       121\n",
      "weighted avg       0.91      0.92      0.91       121\n",
      "\n",
      "Feature importances\n",
      "<BarContainer object of 4 artists>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844425087108014\n"
     ]
    }
   ],
   "source": [
    "print(result[\"search\"].best_score_) # roc-auc best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "6\n",
      "3\n",
      "12\n",
      "false positive rate: 0.0291\n",
      "false discovery rate: 0.3333\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = result[\"test_cm\"].ravel()\n",
    "print(tn)\n",
    "print(tp)\n",
    "print(fp)\n",
    "print(fn)\n",
    "\n",
    "fpr = fp/(fp+tn)\n",
    "print(\"false positive rate: {:.4f}\".format(fpr))\n",
    "fdr = fp/(fp+tp)\n",
    "print(\"false discovery rate: {:.4f}\".format(fdr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65\n",
    "\n",
    "grid_search_clf = result[\"model\"]\n",
    "\n",
    "y_scores = grid_search_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def adjusted_classes(y_scores, t):\n",
    "    \"\"\"\n",
    "    This function adjusts class predictions based on the prediction threshold (t).\n",
    "    Will only work for binary classification problems.\n",
    "    \"\"\"\n",
    "    return [1 if y >= t else 0 for y in y_scores]\n",
    "\n",
    "def precision_recall_threshold(p, r, thresholds, t=0.5, print_cm=True, plot=True):\n",
    "    \"\"\"\n",
    "    plots the precision recall curve and shows the current value for each\n",
    "    by identifying the classifier's threshold (t).\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate new class predictions based on the adjusted_classes\n",
    "    # function above and view the resulting confusion matrix.\n",
    "    y_pred_adj = adjusted_classes(y_scores, t)\n",
    "    cm = confusion_matrix(y_test, y_pred_adj)\n",
    "    \n",
    "    if print_cm:\n",
    "        print(pd.DataFrame(cm,\n",
    "           columns=['pred_neg', 'pred_pos'], \n",
    "           index=['neg', 'pos']))\n",
    "\n",
    "    if plot:\n",
    "        # plot the curve\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.title(\"Precision and Recall curve ^ = current threshold\")\n",
    "        plt.step(r, p, color='b', alpha=0.2,\n",
    "                 where='post')\n",
    "        plt.fill_between(r, p, step='post', alpha=0.2,\n",
    "                         color='b')\n",
    "        plt.ylim([0.5, 1.01]);\n",
    "        plt.xlim([0.5, 1.01]);\n",
    "        plt.xlabel('Recall');\n",
    "        plt.ylabel('Precision');\n",
    "\n",
    "        # plot the current threshold on the line\n",
    "        close_default_clf = np.argmin(np.abs(thresholds - t))\n",
    "        plt.plot(r[close_default_clf], p[close_default_clf], '^', c='k',\n",
    "                markersize=15)\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "     pred_neg  pred_pos\n",
      "neg        37        70\n",
      "pos         0        14\n",
      "0.02\n",
      "     pred_neg  pred_pos\n",
      "neg        47        60\n",
      "pos         0        14\n",
      "0.03\n",
      "     pred_neg  pred_pos\n",
      "neg        54        53\n",
      "pos         1        13\n",
      "0.04\n",
      "     pred_neg  pred_pos\n",
      "neg        60        47\n",
      "pos         1        13\n",
      "0.05\n",
      "     pred_neg  pred_pos\n",
      "neg        64        43\n",
      "pos         1        13\n",
      "0.06\n",
      "     pred_neg  pred_pos\n",
      "neg        68        39\n",
      "pos         1        13\n",
      "0.07\n",
      "     pred_neg  pred_pos\n",
      "neg        73        34\n",
      "pos         1        13\n",
      "0.08\n",
      "     pred_neg  pred_pos\n",
      "neg        74        33\n",
      "pos         1        13\n",
      "0.09\n",
      "     pred_neg  pred_pos\n",
      "neg        76        31\n",
      "pos         2        12\n",
      "0.1\n",
      "     pred_neg  pred_pos\n",
      "neg        76        31\n",
      "pos         2        12\n",
      "0.11\n",
      "     pred_neg  pred_pos\n",
      "neg        78        29\n",
      "pos         2        12\n",
      "0.12\n",
      "     pred_neg  pred_pos\n",
      "neg        78        29\n",
      "pos         3        11\n",
      "0.13\n",
      "     pred_neg  pred_pos\n",
      "neg        78        29\n",
      "pos         3        11\n",
      "0.14\n",
      "     pred_neg  pred_pos\n",
      "neg        78        29\n",
      "pos         4        10\n",
      "0.15\n",
      "     pred_neg  pred_pos\n",
      "neg        80        27\n",
      "pos         4        10\n",
      "0.16\n",
      "     pred_neg  pred_pos\n",
      "neg        81        26\n",
      "pos         4        10\n",
      "0.17\n",
      "     pred_neg  pred_pos\n",
      "neg        82        25\n",
      "pos         4        10\n",
      "0.18\n",
      "     pred_neg  pred_pos\n",
      "neg        82        25\n",
      "pos         4        10\n",
      "0.19\n",
      "     pred_neg  pred_pos\n",
      "neg        83        24\n",
      "pos         4        10\n",
      "0.2\n",
      "     pred_neg  pred_pos\n",
      "neg        84        23\n",
      "pos         4        10\n",
      "0.21\n",
      "     pred_neg  pred_pos\n",
      "neg        86        21\n",
      "pos         4        10\n",
      "0.22\n",
      "     pred_neg  pred_pos\n",
      "neg        89        18\n",
      "pos         5         9\n",
      "0.23\n",
      "     pred_neg  pred_pos\n",
      "neg        91        16\n",
      "pos         5         9\n",
      "0.24\n",
      "     pred_neg  pred_pos\n",
      "neg        91        16\n",
      "pos         5         9\n",
      "0.25\n",
      "     pred_neg  pred_pos\n",
      "neg        92        15\n",
      "pos         5         9\n",
      "0.26\n",
      "     pred_neg  pred_pos\n",
      "neg        93        14\n",
      "pos         5         9\n",
      "0.27\n",
      "     pred_neg  pred_pos\n",
      "neg        94        13\n",
      "pos         5         9\n",
      "0.28\n",
      "     pred_neg  pred_pos\n",
      "neg        95        12\n",
      "pos         5         9\n",
      "0.29\n",
      "     pred_neg  pred_pos\n",
      "neg        95        12\n",
      "pos         5         9\n",
      "0.3\n",
      "     pred_neg  pred_pos\n",
      "neg        97        10\n",
      "pos         5         9\n",
      "0.31\n",
      "     pred_neg  pred_pos\n",
      "neg        98         9\n",
      "pos         5         9\n",
      "0.32\n",
      "     pred_neg  pred_pos\n",
      "neg        99         8\n",
      "pos         5         9\n",
      "0.33\n",
      "     pred_neg  pred_pos\n",
      "neg        99         8\n",
      "pos         5         9\n",
      "0.34\n",
      "     pred_neg  pred_pos\n",
      "neg        99         8\n",
      "pos         5         9\n",
      "0.35\n",
      "     pred_neg  pred_pos\n",
      "neg        99         8\n",
      "pos         5         9\n",
      "0.36\n",
      "     pred_neg  pred_pos\n",
      "neg        99         8\n",
      "pos         5         9\n",
      "0.37\n",
      "     pred_neg  pred_pos\n",
      "neg       100         7\n",
      "pos         5         9\n",
      "0.38\n",
      "     pred_neg  pred_pos\n",
      "neg       100         7\n",
      "pos         6         8\n",
      "0.39\n",
      "     pred_neg  pred_pos\n",
      "neg       101         6\n",
      "pos         7         7\n",
      "0.4\n",
      "     pred_neg  pred_pos\n",
      "neg       102         5\n",
      "pos         7         7\n",
      "0.41\n",
      "     pred_neg  pred_pos\n",
      "neg       103         4\n",
      "pos         7         7\n",
      "0.42\n",
      "     pred_neg  pred_pos\n",
      "neg       103         4\n",
      "pos         7         7\n",
      "0.43\n",
      "     pred_neg  pred_pos\n",
      "neg       103         4\n",
      "pos         7         7\n",
      "0.44\n",
      "     pred_neg  pred_pos\n",
      "neg       104         3\n",
      "pos         7         7\n",
      "0.45\n",
      "     pred_neg  pred_pos\n",
      "neg       105         2\n",
      "pos         7         7\n",
      "0.46\n",
      "     pred_neg  pred_pos\n",
      "neg       105         2\n",
      "pos         7         7\n",
      "0.47\n",
      "     pred_neg  pred_pos\n",
      "neg       105         2\n",
      "pos         7         7\n",
      "0.48\n",
      "     pred_neg  pred_pos\n",
      "neg       105         2\n",
      "pos         8         6\n",
      "0.49\n",
      "     pred_neg  pred_pos\n",
      "neg       105         2\n",
      "pos         8         6\n",
      "0.5\n",
      "     pred_neg  pred_pos\n",
      "neg       105         2\n",
      "pos         8         6\n",
      "0.51\n",
      "     pred_neg  pred_pos\n",
      "neg       105         2\n",
      "pos         8         6\n",
      "0.52\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos         8         6\n",
      "0.53\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos         9         5\n",
      "0.54\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos         9         5\n",
      "0.55\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos         9         5\n",
      "0.56\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos         9         5\n",
      "0.57\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos         9         5\n",
      "0.58\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos         9         5\n",
      "0.59\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos         9         5\n",
      "0.6\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        11         3\n",
      "0.61\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        11         3\n",
      "0.62\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        11         3\n",
      "0.63\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        11         3\n",
      "0.64\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        11         3\n",
      "0.65\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        11         3\n",
      "0.66\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        11         3\n",
      "0.67\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        11         3\n",
      "0.68\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        11         3\n",
      "0.69\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        11         3\n",
      "0.7\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        11         3\n",
      "0.71\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        11         3\n",
      "0.72\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        12         2\n",
      "0.73\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        12         2\n",
      "0.74\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        12         2\n",
      "0.75\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        12         2\n",
      "0.76\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        12         2\n",
      "0.77\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        12         2\n",
      "0.78\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        12         2\n",
      "0.79\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        14         0\n",
      "0.8\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        14         0\n",
      "0.81\n",
      "     pred_neg  pred_pos\n",
      "neg       106         1\n",
      "pos        14         0\n",
      "0.82\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.83\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.84\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.85\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.86\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.87\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.88\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.89\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.9\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.91\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.92\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.93\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.94\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.95\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.96\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.97\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.98\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n",
      "0.99\n",
      "     pred_neg  pred_pos\n",
      "neg       107         0\n",
      "pos        14         0\n"
     ]
    }
   ],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "for i in np.arange(1, 100):\n",
    "    t = i/100\n",
    "    print(t)\n",
    "    precision_recall_threshold(p, r, thresholds, t, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_rates = np.array([])\n",
    "fd_rates = np.array([])\n",
    "\n",
    "for i in np.arange(1, 100):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    result = run_single(X_train, y_train, X_test, y_test, rf_model)\n",
    "    \n",
    "    tn, fp, fn, tp = result[\"test_cm\"].ravel()\n",
    "    \n",
    "    fp_rates = np.append(fp_rates, (fp)/(fp+tn))    \n",
    "    fd_rates = np.append(fd_rates, (fp)/(fp+tp))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0298 (+- 0.0179)\n",
      "0.3516 (+- 0.1608)\n"
     ]
    }
   ],
   "source": [
    "print (\"{:.4f} (+- {:.4f})\".format(fp_rates.mean(), fp_rates.std()))\n",
    "print (\"{:.4f} (+- {:.4f})\".format(fd_rates.mean(), fd_rates.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
